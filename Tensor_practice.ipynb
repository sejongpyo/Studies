{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello, Tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, Tensorflow!\")\n",
    "\n",
    "sess = tf.Session() # start tf session\n",
    "\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(99, name = 'x')\n",
    "y = tf.Variable(x + 20, name = 'y')\n",
    "\n",
    "# 변수 초기화\n",
    "model = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    print(session.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.6269462 [0.15756832] [-0.09103607]\n",
      "200 0.0030052348 [0.9363299] [0.14473702]\n",
      "400 0.0011475434 [0.9606558] [0.0894387]\n",
      "600 0.00043818975 [0.9756877] [0.05526763]\n",
      "800 0.00016732143 [0.9849765] [0.03415198]\n",
      "1000 6.38922e-05 [0.9907164] [0.02110391]\n",
      "1200 2.4396597e-05 [0.9942633] [0.01304086]\n",
      "1400 9.315808e-06 [0.996455] [0.00805852]\n",
      "1600 3.5573055e-06 [0.99780947] [0.00497967]\n",
      "1800 1.3584267e-06 [0.9986463] [0.00307724]\n",
      "2000 5.1884103e-07 [0.9991634] [0.00190169]\n"
     ]
    }
   ],
   "source": [
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'score')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.43201566 [1.412326] [0.42104226]\n",
      "200 0.005738411 [1.412326] [0.19952197]\n",
      "400 0.0021912097 [1.412326] [0.12329248]\n",
      "600 0.00083671 [1.412326] [0.07618717]\n",
      "800 0.00031949618 [1.412326] [0.04707903]\n",
      "1000 0.000121999175 [1.412326] [0.02909198]\n",
      "1200 4.6584344e-05 [1.412326] [0.01797698]\n",
      "1400 1.7788716e-05 [1.412326] [0.01110881]\n",
      "1600 6.7926917e-06 [1.412326] [0.0068646]\n",
      "1800 2.5937322e-06 [1.412326] [0.00424195]\n",
      "2000 9.906771e-07 [1.412326] [0.00262141]\n"
     ]
    }
   ],
   "source": [
    "S = tf.Variable(tf.random_normal([1]), name = 'score')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "hypothesis = X * S + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict = {X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9968557]\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "print(sess.run(hypothesis, feed_dict = {X: [5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비용함수 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+VhCQQEiBkIUDClhBkDTuIoIAoKgpaW6SKaB+LbaW1ra21q63+2tL2qVZrrVJFUZHWBQriiogsgkDYdwIkhD0LEEhC1rl+f2TsQ5FlQjJzZrner1deZ86Q5HzZvhzuc859i6pijDEm8IQ5HcAYY8zlsQI3xpgAZQVujDEBygrcGGMClBW4McYEqAhfHiwhIUE7duzoy0MaY0zAW7duXZGqJp77vk8LvGPHjmRnZ/vykMYYE/BEZP/53rchFGOMCVBW4MYYE6CswI0xJkBZgRtjTICyAjfGmABlBW6MMQHKCtwYYwJUQBT48pxCnv10j9MxjDHGrwREga/IKeKJj3ZTcLrC6SjGGOM3AqLAJw5MpcalvLXuoNNRjDHGbwREgXdObM7gTvH8a+0BXC5bQcgYYyBAChxg0qA09heXs2pfsdNRjDHGLwRMgY/t2YYWTZswZ02+01GMMcYvBEyBRzcJ59a+7fho2zGOl1U5HccYYxwXMAUOdcMoVbUu5q63i5nGGBNQBZ7ZJpa+aS2ZsyYfVbuYaYwJbQFV4ACTBqaxt7CM7P0nnI5ijDGOumSBi0imiGw86+OUiHxfROJFZJGI5Li3rXwReFyfFJpHRdjFTGNMQCg4VcG4vy5n3f7jjf69L1ngqrpLVbNUNQvoD5QD84BHgMWqmgEsdu97XbPICMZnteXdzUcoKa/2xSGNMeayvZF9gK2HThEfE9Xo37u+Qyijgb2quh8YD8xyvz8LmNCYwS7mzsEdqKxx8bZdzDTG+LFalzJnzQGGpbemU0JMo3//+hb4HcAc9+tkVT0C4N4mNWawi+neNo6s1JbMXr3fLmYaY/zW0t0FHDp5hjsHd/DK9/e4wEUkErgFeLM+BxCRqSKSLSLZhYWF9c13QXcOrruYuTq38ceVjDGmMby+Op/E2CjGdE/2yvevzxn4DcB6VT3m3j8mIikA7m3B+b5IVWeo6gBVHZCYmNiwtGcZ17stcdERvL7aLmYaY/zPoZNn+GRnARMHpNIk3Ds3/NXnu07i/4ZPABYAU9yvpwDzGyuUJ5pGhnNbv/a8v/UIRaWVvjy0McZc0r/W5KPAHYNSvXYMjwpcRJoBY4C5Z709HRgjIjnuH5ve+PEu7s7BaVTX2jSzxhj/Ul3r4p9rD3BN10Tat2rmteN4VOCqWq6qrVW15Kz3ilV1tKpmuLc+H4zOSI5lUKd45qzJt2lmjTF+Y/GOAgpOV3rt4uUXAu5JzHPdObhumtnP9hY5HcUYYwCYvXo/KS2iuSaz8a77nU/AF/jYnm2Ij4nktc/3Ox3FGGPYX1zG8pwiJg5MJcJLFy+/EPAFHhURztcGpPLxjgKOlJxxOo4xJsS99vl+IsKESYPSvH6sgC9wqBtGcakyx24pNMY4qKK6ljeyD3J9jzYkx0V7/XhBUeCp8c0YlZnE62sOUFXjcjqOMSZEvbPpMCVnqpk81LsXL78QFAUOcNfQDhSVVvLhtqNORzHGhKhXP99PRlLdIuy+EDQFfnVGImnxzXh1lV3MNMb43qYDJ9l8sITJQzsgIj45ZtAUeFiYcNeQNNbkHWfn0VNOxzHGhJhXP99PTGTd2r2+EjQFDvDV/qlERYTZWbgxxqdOlFXxzqbD3NqvHbHRTXx23KAq8FYxkdzcpy3zNhzidIUt9mCM8Y031x2gssbF5CEdfXrcoCpwgMlDOlBeVcvc9YecjmKMCQG1LuW1z/MZ1CmezDaxPj120BV4n9SW9EltyaxVeTY/ijHG6z7dVUD+8XLu9tGtg2cLugIHuOfKDuwrLGPFHpsfxRjjXS+vzKNNXDTX92jj82MHZYHf2CuFhOZRvLwyz+koxpggtqeglOU5RUwe2sFrizZcTFAWeFREOF8fnMaSXQXsLy5zOo4xJki9siqPyIgw7hjovUUbLiYoCxzq5kcJF+EVu6XQGOMFpyqqeWvdQW7u3ZbWzaMcyRC0BZ4cF82NvVJ4Y+0ByiprnI5jjAkyb2UfpLyqlnuu7OhYhqAtcIApV3bkdGUNczfYLYXGmMbjcimvrMqjf4dW9GrfwrEcnq6J2VJE3hKRnSKyQ0SGiki8iCwSkRz3tpW3w9ZXv7SW9GrXgldW5qFqtxQaYxrH0t2F5BWXM8XBs2/w/Az8KeADVe0G9AF2AI8Ai1U1A1js3vcrIsI9V3Ykp6CUz/YUOx3HGBMkXlqZR3JcFDf09P2tg2e7ZIGLSBwwAngRQFWrVPUkMB6Y5f60WcAEb4VsiHF9UkhoHsnMz3KdjmKMCQJ7Ck6zbHchdw125tbBs3ly9M5AIfCSiGwQkRdEJAZIVtUjAO5t0vm+WESmiki2iGQXFhY2WnBPRUWEc9eQDnyys4B9haU+P74xJrjM/CyPqIgwvj7Y+0umXYonBR4B9AP+rqp9gTLqMVyiqjNUdYCqDkhM9O4KzRdy5+AORIaH8dJneY4c3xgTHE6UVTF3/UFu7dvOsVsHz+ZJgR8EDqrqavf+W9QV+jERSQFwbwu8E7HhEmOjGJ/VlrfWHaSk3GYpNMZcntfX5FNR7eIbV3VyOgrgQYGr6lHggIhkut8aDWwHFgBT3O9NAeZ7JWEjuXdYJ85U1zJnrS18bIypv+paF6+symN4RgJdk3076+CFeDoC/11gtohsBrKA3wHTgTEikgOMce/7re5t47iyS2tmrcyjutYWPjbG1M97W45w7FSl35x9g4cFrqob3ePYvVV1gqqeUNViVR2tqhnu7XFvh22obwzrxJGSCj7YagsfG2M8p6rMXJFL58QYrs5w5lre+QT1k5jnGtUtiY6tm9kthcaYelmff4JNB0u4d1gnwsJ8s2CxJ0KqwMPChHuHdWJD/knW7T/hdBxjTIB4YXkuLZo24Sv9fLdgsSdCqsABbu/fnrjoCF5Yvs/pKMaYALC/uIwPtx3lzsFpNIuMcDrOfwm5Ao+JiuCuIR34YNtRmyvcGHNJM1fkEh4mjs46eCEhV+AA91zZkYgwYeYKGws3xlzYyfIq3sg+yISsdiTFRTsd50tCssCT4qIZn9WON7IPcqKsyuk4xhg/NXt1Pmeqa7lveGeno5xXSBY4wDeHd+ZMdS2zV9uKPcaYL6usqeWlz/K4umsimW3848Gdc4VsgWe2ieXqrom8vHI/lTW1TscxxviZ+RsOU1RaydQR/nn2DSFc4FB3Fl5UWsn8DYedjmKM8SMulzJj+T6uSKl7gttfhXSBD0tvzRUpcfxj+T5cLluxxxhTZ+nuQvYUlDJ1RCdE/OfBnXOFdIGLCFNHdCKnoJQlu/x2MkVjjI89t3QvKS2iGde7rdNRLiqkCxxgXO+2tGvZlOeW7nU6ijHGD2zIP8Hq3OP8z1WdHF9x51L8O50PNAkP477hnVibd4LsPL+fj8sY42XPLd1Li6ZNmDTI+RV3LiXkCxxg4sBUWjVrYmfhxoS4PQWlfLT9GHcP7UBMlH89Nn8+VuBAs8gIplzZkY93FLD72Gmn4xhjHDJj2V4iw8OY4oePzZ+PFbjblKEdadoknOeX2iRXxoSioyUVzNtwiK8NSCXBD9a79IQVuFurmEgmDkxl/sZDHDp5xuk4xhgfm/lZLi7Frx/cOZdHBS4ieSKyRUQ2iki2+714EVkkIjnubSvvRvW++4bXLZX04nKb5MqYUFJypprXV+dzU68UUuObOR3HY/U5Ax+pqlmqOsC9/wiwWFUzgMXu/YDWvlUzbunTljlr8jluk1wZEzJeXZVHaWUN918dOGff0LAhlPHALPfrWcCEhsdx3rev6cKZ6lpetmXXjAkJ5VU1vLgil5GZifRo28LpOPXiaYEr8JGIrBORqe73klX1CIB7m+SNgL6WkRzL2B5teHllHqcrqp2OY4zxsjlrDnCivJppo9KdjlJvnhb4MFXtB9wAPCAiIzw9gIhMFZFsEckuLCy8rJC+9sDIdE5V1PDq5zbVrDHBrLKmlhnL9jK4Uzz9O8Q7HafePCpwVT3s3hYA84BBwDERSQFwb887mYiqzlDVAao6IDExsXFSe1mv9i0Y0TWRF5fncqbKppo1Jli9ve4Qx05VBuTZN3hQ4CISIyKxX7wGrgO2AguAKe5PmwLM91ZIJ0wbmU5xWRX/WpvvdBRjjBfU1Lp4bule+rRvwVXpCU7HuSyenIEnAytEZBOwBnhXVT8ApgNjRCQHGOPeDxqDOsUzqGM8zy/bR1WNy+k4xphG9s7mw+QfL+eBkel+PWXsxVyywFV1n6r2cX/0UNXfut8vVtXRqprh3gbdTFAPjErnSEkF8zYcdDqKMaYRuVzKs0v2kpkcy7VXJDsd57LZk5gXMSIjgV7tWvDsp3upqbWzcGOCxYfbjpJTUMp3RnYhLCwwz77BCvyiRITvjkpnf3E58zfasmvGBAOXS3lqcQ6dE2L8fsGGS7ECv4Qx3ZO5IiWOZ5bssbNwY4LAR9uPsfPoaaaNSic8gM++wQr8kkSEB0enk1tUxsLNR5yOY4xpAFXl6cU5dGxdN21GoLMC98B13dvQrU0sT3+SQ60tfmxMwPp4RwHbj5xi2qgMIvx8uTRPBP7PwAfCwoTvjc5gX2EZCzfbWLgxgUhVeWrxbtLimzEhK/DPvsEK3GNje7Sha3Jz/vrJHjsLNyYAfbKzgK2HTjFtZHpQnH2DFbjHwsKE747KYE9BKe9tsbFwYwLJF2PfqfFNubVfO6fjNBor8Hq4sVcK6UnNeWqxjYUbE0g+2VnApoMlPHBNOk2C5OwbrMDrJTxM+P61dWfh72yysXBjAoGq8sSiurHvr/Rv73ScRmUFXk839kyhW5tYnlqcY/eFGxMAPtx2jG2HT/G90RlBdfYNVuD1FhYm/GBMV3KLypi34ZDTcYwxF+FyKU8u2k3nhJigufPkbFbgl+G67sn0ateCpz/JodrOwo3xW+9uOcKuY6d58NrguO/7XMH3M/IBEeGHY7py4PgZ3sy2mQqN8Ue1LuUvH++ma3Jzbg7wOU8uxAr8Ml2TmUjftJY880kOlTW2ao8x/mb+xkPsLSzjB9d2DegZBy/GCvwyiQgPjcnkcEkFc1bbqj3G+JPqWhdPLc7hipQ4ru/Rxuk4XmMF3gDD0lszpHM8zyzZQ1lljdNxjDFu/1p7gP3F5fzouuA9+wYr8AYRER4e242i0ipe+izX6TjGGOBMVS1PL85hQIdWjOqW5HQcr/K4wEUkXEQ2iMhC9368iCwSkRz3tpX3YvqvfmmtGNM9meeX7eNkeZXTcYwJebNW5VFwupKHx3YL2LUuPVWfM/AHgR1n7T8CLFbVDGCxez8k/ei6TEora/j70r1ORzEmpJWcqebvn+7lmsxEBnWKdzqO13lU4CLSHrgJeOGst8cDs9yvZwETGjda4MhsE8utWe14+bM8jpZUOB3HmJA1Y9leSs5U8+PrM52O4hOenoH/BXgYOPuplWRVPQLg3p53sElEpopItohkFxYWNiisP/vBmK64VHn6kxynoxgTkgpOVzBzRR4392lLj7YtnI7jE5cscBEZBxSo6rrLOYCqzlDVAao6IDEx8XK+RUBIjW/GpEFp/GvtAXKLypyOY0zI+dsne6iqdfHDMV2djuIznpyBDwNuEZE84J/AKBF5DTgmIikA7m2B11IGiGmj0omKCON/P9zldBRjQkpeURmzV+czcWAqnRJinI7jM5cscFX9qaq2V9WOwB3AJ6p6F7AAmOL+tCnAfK+lDBBJsdFMHdGZd7ccYUP+CafjGBMy/vThLiIjwvj+tRlOR/GphtwHPh0YIyI5wBj3fsj75vDOJDSP4vfv7UTVFn0wxts25J/g3S1HmDqiM0mx0U7H8al6Fbiqfqqq49yvi1V1tKpmuLfHvRMxsMRERfCDMRmsyTvOxztCflTJGK9SVX7/3k4SmkfxzeGdnY7jc/YkphdMHJBK58QYpr+/wxZ9MMaLFm0/xpq843z/2gxioiKcjuNzVuBeEBEexiNju7G3sIx/ZR9wOo4xQamm1sX0D3bSOTGGiQNTnY7jCCtwLxnTPZmBHVvx5KIcm+jKGC/4V/YB9hWW8ZOx3YJuqTRPhebP2gdEhJ/deAVFpZU8Z4/YG9OoTldU8+Si3Qzs2Irruic7HccxVuBe1DetFeOz2jJj2T4OnTzjdBxjgsbfluylqLSKX47rHvQTVl2MFbiXPTy2GwB/eH+nw0mMCQ75xeXMXJHLbf3a0bt9S6fjOMoK3MvatWzK1BGdWbDpMOvt4R5jGmz6BzsIDxMevr6b01EcZwXuA9+6ugtJsVE8vnC7PdxjTAOsyT3Oe1uOcv/VnWnTIrQe2jkfK3AfiImK4EfXZ7Ih/yQLNh12Oo4xAcnlUh5fuJ02cXVTVhgrcJ+5vV97erSN4w/v7+RMla1ib0x9zd1wiC2HSvjJDZk0iwy9h3bOxwrcR8LChEdv7sHhkgpbuceYejpdUc3093fSJ7Ul4/u0czqO37AC96FBneK5pU9bnlu6lwPHy52OY0zA+Osneyguq+SxW3oE9Srz9WUF7mM/vbEb4SL8v3e3Ox3FmICwp6CUmSty+Vr/VPqkhvZtg+eyAvexlBZNmTYqnQ+3HWN5TvAuMWdMY1BVfvPONppGhvPjsaGxzmV9WIE74L7hnejQuhm/XrCNqhqbrdCYC1m0/RjLc4r4wbVdSWge5XQcv2MF7oCoiHB+Na47ewvLeGVVntNxjPFLFdW1PP7udromN2fy0A5Ox/FLVuAOGdUtiWsyE/nLxzkcLalwOo4xfqfuYv8ZHr25R8jONngpnqxKHy0ia0Rkk4hsE5HfuN+PF5FFIpLj3rbyftzgISL8+uYeVNW67IKmMefIKyrj2U/3cnOftgxLT3A6jt/y5J+1SmCUqvYBsoCxIjIEeARYrKoZwGL3vqmHjgkxPHBNOgs3H7ELmsa4qSq/WrCNyPAwfnnTFU7H8WuerEqvqlrq3m3i/lBgPDDL/f4sYIJXEga5+6/uTKeEGH41fxsV1faEpjHvbTnKst2FPHRdV5LibL6Ti/FoYElEwkVkI1AALFLV1UCyqh4BcG+TLvC1U0UkW0SyCwvtLPNc0U3CeWx8D3KLypixbJ/TcYxxVGllDY8t3EaPtnFMHmIXLi/FowJX1VpVzQLaA4NEpKenB1DVGao6QFUHJCYmXm7OoDY8I5FxvVN4Zske9heXOR3HGMc8uWg3Bacr+X8TehJhFy4vqV6/Qqp6EvgUGAscE5EUAPe2oNHThZBfjuteN+Y3f5tNOWtC0rbDJby8Mo9Jg9Lom2b3RHjCk7tQEkWkpft1U+BaYCewAJji/rQpwHxvhQwFyXHR/Pj6TJbtLmT+Rpty1oSWmloXj7y9hVbNmvDw9fbEpac8OQNPAZaIyGZgLXVj4AuB6cAYEckBxrj3TQPcNaQDWakteWzhdo6XVTkdxxifeXllHlsOlfDozT1o2SzS6TgBw5O7UDaral9V7a2qPVX1Mff7xao6WlUz3Nvj3o8b3MLDhOlf6cWpM9V2b7gJGQeOl/Pnj3YzqlsS43qnOB0noNhVAj/TrU0c37q6C3PXH7J7w03QU1V+/u+thAk8PqFnSK8wfzmswP3QtFHpdE6I4efzttrqPSaoLdh0mGW7C/nR9Zm0a9nU6TgBxwrcD0U3Ced3t/Ui/3g5Tyza5XQcY7yiuLSSx97ZTlZqS+4e2tHpOAHJCtxPDencmkmD0nhxRS7r9p9wOo4xje7RBds4VVHN9K/0ItxW2bksVuB+7Gc3dqNNXDQPv7XJHrM3QeWDrUdYuPkID47OoFubOKfjBCwrcD8WG92E6V/pzd7CMv7ycY7TcYxpFCfKqvjFv7fSs10c91/dxek4Ac0K3M+N6JrIHQNTmbFsLxsPnHQ6jjEN9ut3tlFyppo/3d7H5vluIPvVCwA/u+mKuic137ShFBPYPtx2lPkbD/PdURlckWJDJw1lBR4A4qKb8PvbepFTUMqTH+92Oo4xl+V4WRU/n7eV7ilxfPsaGzppDFbgAeKazCQmDUplxrJ9rMm1h15NYFFVfjZ3C6fOVPPERBs6aSz2qxhAfnFTd1JbNeOHb2zkdEW103GM8djc9Yf4YNtRHrquq9110oiswANITFQET07sw+GTZ3h8oc2VYgLDwRPlPLpgG4M6xXPf8M5OxwkqVuABpn+HeL59TRfeyD7IR9uOOh3HmItyuZSH3tgEwJ+/2sce2GlkVuAB6MHRXenRNo6fzt1C4elKp+MYc0Evrshlde5xfnVzd1LjmzkdJ+hYgQegyIgwnpyYRWllDT96cxMul63gY/zP1kMl/PHDnVzXPZmv9m/vdJygZAUeoLomx/KLcd1ZuruQmZ/lOh3HmP9SVlnD9+ZsoHVMFH/4Sm+bJtZLrMAD2F2D07iuezJ/+GAnWw+VOB3HmP/49YJt5BaX8Zc7smgVYyvseIsVeAATEf7wld60joniu3M2UFZZ43QkY5i/8RBvrjvItJHpDOnc2uk4Qc2TRY1TRWSJiOwQkW0i8qD7/XgRWSQiOe6tLSPtgFYxkTw5MYu84jIeXbDN6TgmxB04Xs4v5m2lX1pLHhyd4XScoOfJGXgN8JCqXgEMAR4Qke7AI8BiVc0AFrv3jQOGdmnNtJHpvLXuIG+vO+h0HBOiKmtqmfb6ehB46o6+RNjTll7nyaLGR1R1vfv1aWAH0A4YD8xyf9osYIK3QppLe3B0BoM7xfOLf29l97HTTscxIeh37+5g08ES/nR7H7tl0Efq9U+kiHQE+gKrgWRVPQJ1JQ8kXeBrpopItohkFxbaIr3eEhEexl8n9SUmKpxvv7bOxsONT72z6TCzVu3nvqs6MbZnG6fjhAyPC1xEmgNvA99X1VOefp2qzlDVAao6IDEx8XIyGg8lxUXz9B19yS0q42fztqBq94cb79tbWMojb2+mX1pLfnJDN6fjhBSPClxEmlBX3rNVda777WMikuL+8RSgwDsRTX1cmZ7AD67tyvyNh5m9Ot/pOCbInamq5TuvrScyIoxnvt7PZhn0MU/uQhHgRWCHqj5x1g8tAKa4X08B5jd+PHM5HhiZzoiuiTz2znY25NuCyMY7VJWfzdvCrmOneXJiFm1bNnU6Usjx5J/LYcBkYJSIbHR/3AhMB8aISA4wxr1v/EBYmPDUxCyS4qL41mvrKDhd4XQkE4Re+iyPeRsO8YNru3JN5nkvgRkv8+QulBWqKqraW1Wz3B/vqWqxqo5W1Qz31lYZ8COtYiKZMXkAJWeq+c5r66mqcTkdyQSRlXuL+O17O7iuezLfHZXudJyQZQNWQax72zj+eHsfsvef4LGF9pCPaRwHT5Qz7fUNdGzdjD9/rQ9hNkWsYyKcDmC865Y+bdl6qIQZy/bRq10LJg5MczqSCWAV1bV867V1VNe4mHH3AGKjmzgdKaTZGXgIePj6TIZnJPCLf2+19TTNZXO5lIfe3MS2w6d4cmIWXRKbOx0p5FmBh4CI8DCemdSP1FbNuP/VbPYXlzkdyQSgvyzO4d3NR/jJ2G5c2z3Z6TgGK/CQ0aJZE168ZyAuhW+8vJaSM7YosvHcvzcc4unFOXy1f3vuH2HrWvoLK/AQ0ikhhufu6s/+4nKmvb6emlq7M8Vc2rr9J3j47c0M6hTPb2/tZYsz+BEr8BAztEtrfntrT5bnFPGrBdvscXtzUfnF5dz/ajYpLaJ5/q7+REZYZfgTuwslBE0cmEZuUTnPLd1Lu5ZNeWCk3cdrvqy4tJIpL62hxqW8OGWgrazjh6zAQ9TD12dytOQMf/pwF0mxUXx1QKrTkYwfKa+q4Ruzsjl88gyz7xtMepLdceKPrMBDVFiY8Mfb+1BYWskjc7eQGBtlj0MbAGpqXXz39Q1sOXiSv9/VnwEd452OZC7ABrRCWGREGM/d1Z/M5Fi+M3s9mw+edDqScZiq8sv5W1m8s4DfjO/J9T1sbm9/ZgUe4mKjm/DyvQOJj4lkysw15NhqPiFLVZn+/k7mrDnAtJHpTB7SwelI5hKswA1JcdHMvm8wTcLDuPOF1eQXlzsdyTjgb0v28PyyfUwe0oGHruvqdBzjAStwA0CH1jG8dt9gqmpdfP2FzzlaYlPQhpKXPsvlfz/azW192/GbW3rYvd4Bwgrc/EfX5Fhe+cYgTpZXc+cLn1NUWul0JOMDb2Qf4DfvbOf6Hsn88fbeNrtgALECN/+ld/uWzLxnIIdOnuHr/7ASD3ZvrTvIT97ezPCMBJ6e1JcIWxItoNjvlvmSQZ3imTllIPnHy63Eg9ib2Qf48VubGNYlgX/cPYCoiHCnI5l68mRNzJkiUiAiW896L15EFolIjnvbyrsxja9dmZ7AzHvqSnzSjM8pPG0lHkzeWHuAh9/ezFXpCbwwZQDRTay8A5EnZ+AvA2PPee8RYLGqZgCL3fsmyFzZJYGX7hnEwRNnmPSPzyk4ZRc2g8E/1+Tzk7mbGZ6RyD/utvIOZJ6sibkMOHcVgPHALPfrWcCERs5l/MTQLq156d6BHD55htufW2W3GAa4Gcv28sjcLYzISGTG5P5W3gHucsfAk1X1CIB7e8FnsEVkqohki0h2YWHhZR7OOGlI59a8/s0hnKqo5vbnVrLrqD3sE2hUlT9+sJPfvbeTcb1T7Mw7SHj9IqaqzlDVAao6IDEx0duHM16SldqSN+8figh87flVrM8/4XQk46Fal/KLf2/l2U/38vXBaTx1R1+bFjZIXO7v4jERSQFwbwsaL5LxVxnJsbz1rStp2awJd/5jNR9vP+Z0JHMJFdW1fHfOemavzufb13ThtxN6Em73eQeNyy3wBcAU9+spwPzGiWP8XWp8M9781lAykpsz9dVsXlmV53QkcwHFpZVM+sfnvL/1KL+46Qp+MrabPWEZZDy5jXAOsArIFJGDIvI/wHRgjIjkAGPc+yZEJMVG88+pQxjVLZlfzd/G4wu3U+uylX38yd7CUm59diU7jjPW9T4AAAqxSURBVJzi73f2577hto5lMLrkfOCqOukCPzS6kbOYANIsMoLnJ/fn8YXbeXFFLgeOl/PExCyaR9kU805bubeIb7+2nogwYc43h9A3zR7TCFZ2JcNctvAw4de39ODRm7vz8Y5j3Pq3z8grKnM6VshSVV5ckcvkF9eQGBvFvO8Ms/IOclbgpsHuHdaJV74xmMLSSm55ZgWf7rJr2r5WUV3LQ29s4vGF2xndLYl/PzCMtNbNnI5lvMwK3DSKqzISeGfaVbRr1Yx7X17LM5/k4LJxcZ84cLycrz63inkbD/HDMV157q7+NpQVIqzATaNJjW/G3G9fyc292/K/H+1myktrbA4VL3tvyxFufHo5ecVlvHD3AL43OsOmgw0hVuCmUTWNDOepO7L4/W29WJN7nBueWs6KnCKnYwWdiupafj5vC9+ZvZ4uic1573vDGX1FstOxjI9ZgZtGJyJMGpTGgmlX0apZEybPXM3v399BRXWt09GCwvbDp5jwt8+YvTqf+0d05s1vDSU13sa7Q5EVuPGazDaxLJh2FXcMTOX5pfu4+a8rbOX7BqiudfH04hxueWYFRaVVvHTvQH564xU0sUUYQpb9zhuvahoZzu9v681L9w7kVEU1tz67kj9/tIuqGpfT0QLKrqOnue3ZlTyxaDc39kph0Q9GMDLzgnPImRAhqr67U2DAgAGanZ3ts+MZ/1JSXs1vFm5j7vpDdEmM4fEJPbmyS4LTsfxaeVUNf/1kDy8s30dsdBN+O6EnN/RKcTqW8TERWaeqA770vhW48bUlOwv41YKtHDh+hglZbfnZTVeQFBvtdCy/oqos2n6M37yznUMnz/CVfu352Y3daN08yuloxgEXKnC7WdT43MhuSSzqcjXPLtnDc0v3sXhHAdNGpTPlyo42RzV1wyW/f38Hn+4qJDM5ljfuH8qgTvFOxzJ+yM7AjaNyi8p47J1tLNlVSLuWTXnouq5MyGoXkvcyHy2p4IlFu3hr3UFioiL43qgM7hnW0S5SGhtCMf5t5d4ipr+/k80HS7giJY4HR6dzXfc2IVHkBacreHF5LrNW5eFywd1DO/DAyHRaxUQ6Hc34CStw4/dcLuXdLUd4YtFucovKyEhqzndGduHm3m2JCMKz0EMnz/D80r38a+0BqmtdjM9qxw/HdLV7us2XWIGbgFHrLvJnl+xh59HTpMY3ZfKQDny1f2rAn5WqKuvzT/LqqjwWbj6CCNzWtz3fvqYLHRNinI5n/JQVuAk4LpeyeGcB/1i+jzW5x4mKCOPmPm25c3AaWaktA2p1mdLKGhZuOswrq/az/cgpYqMiuH1Ae745vDNtWzZ1Op7xc1bgJqDtPHqKV1ftZ96GQ5RX1dKxdTNuyWrH+Ky2dEls7nS886qsqWXprkLmbzrMx9uPUVnjolubWO4e2pHxWW2JsRkDjYeswE1QOF1RzftbjjJ/0yFW7i1GFbq1iWVktyRGZibRL62lo+PlRaWVLN1VyJJdBSzbXcipihriYyIZ1zuF8Vnt6JcWWP9zMP7BKwUuImOBp4Bw4AVVvejamFbgpjEdO1XBO5sO8/GOY2TnnaDGpcRFRzCoU2v6d2hFv7SW9G7fkqaR3rm3XFU5XFLBuv0nWL//BNn7j7P10CkAEppHcU1mIjf1TuGq9AS7FdA0SKMXuIiEA7upW9T4ILAWmKSq2y/0NVbgxltOVVTzWU4RS3YVsDbvBLnupd0iwoROCTGkJzUnPak5XRKbk9IimsTYKJLioomJDL/oGXGtSykuq6TgVCWFpZXkF5ezp6CUnILT7Ckopai0CoDoJmH0bt+S4ekJjOyWRPeUuJC4BdL4hjeexBwE7FHVfe4D/BMYD1ywwI3xlrjoJtzQK+U/84QUl1ayIf8kGw6cYNfRUnYePc2H245y7iJBURFhNI0MJyoijKiIcCLChMoaF5U1tVRWuyirqvnS18RGRdAlqTnXZCbRs20c/TvE0y0l1s6yjc81pMDbAQfO2j8IDD73k0RkKjAVIC0trQGHM8ZzrZtHcW33ZK7t/n+LHFTW1JJfXM6xU5UUnK6g8HQlxWVVVFTXlXVlTS3VLiUqIozoJnWl3jwqgqTYKBJjo0iMjaZ9q6YkxUbZOLbxCw0p8PP9Cf7SeIyqzgBmQN0QSgOOZ0yDREWEk5EcS0ZyrNNRjGkUDfk/30Eg9az99sDhhsUxxhjjqYYU+FogQ0Q6iUgkcAewoHFiGWOMuZTLHkJR1RoRmQZ8SN1thDNVdVujJTPGGHNRDXoUTFXfA95rpCzGGGPqwe57MsaYAGUFbowxAcoK3BhjApQVuDHGBCifzkYoIoXA/sv88gSgqBHjNCZ/zeavucB/s/lrLvDfbP6aC/w3W31zdVDVxHPf9GmBN4SIZJ9vMhd/4K/Z/DUX+G82f80F/pvNX3OB/2ZrrFw2hGKMMQHKCtwYYwJUIBX4DKcDXIS/ZvPXXOC/2fw1F/hvNn/NBf6brVFyBcwYuDHGmP8WSGfgxhhjzmIFbowxASqgClxEHheRzSKyUUQ+EpG2TmcCEJE/ichOd7Z5ItLS6UxfEJGvisg2EXGJiOO3U4nIWBHZJSJ7ROQRp/N8QURmikiBiGx1OsvZRCRVRJaIyA737+ODTmf6gohEi8gaEdnkzvYbpzOdTUTCRWSDiCx0OsvZRCRPRLa4e6xBiwQHVIEDf1LV3qqaBSwEfuV0ILdFQE9V7U3dQs8/dTjP2bYCtwHLnA7iXgj7b8ANQHdgkoh0dzbVf7wMjHU6xHnUAA+p6hXAEOABP/o1qwRGqWofIAsYKyJDHM50tgeBHU6HuICRqprV0HvBA6rAVfXUWbsxnGcJNyeo6keqWuPe/Zy61Yn8gqruUNVdTudw+89C2KpaBXyxELbjVHUZcNzpHOdS1SOqut79+jR1hdTO2VR1tE6pe7eJ+8Mv/k6KSHvgJuAFp7N4U0AVOICI/FZEDgB34j9n4Gf7BvC+0yH81PkWwvaLMgoEItIR6AusdjbJ/3EPU2wECoBFquov2f4CPAy4nA5yHgp8JCLr3Iu+Xza/K3AR+VhEtp7nYzyAqv5cVVOB2cA0f8nl/pyfU/df3tm+yuVpNj/h0ULY5stEpDnwNvD9c/4n6ihVrXUPabYHBolIT6czicg4oEBV1zmd5QKGqWo/6oYSHxCREZf7jRq0Io83qOq1Hn7q68C7wKNejPMfl8olIlOAccBo9fHN9fX4NXOaLYR9GUSkCXXlPVtV5zqd53xU9aSIfErddQSnLwQPA24RkRuBaCBORF5T1bsczgWAqh52bwtEZB51Q4uXdY3K787AL0ZEMs7avQXY6VSWs4nIWOAnwC2qWu50Hj9mC2HXk4gI8CKwQ1WfcDrP2UQk8Ys7rkSkKXAtfvB3UlV/qqrtVbUjdX/GPvGX8haRGBGJ/eI1cB0N+AcvoAocmO4eGthM3U/cX26pegaIBRa5bw16zulAXxCRW0XkIDAUeFdEPnQqi/tC7xcLYe8A3vCXhbBFZA6wCsgUkYMi8j9OZ3IbBkwGRrn/bG10n1n6gxRgifvv41rqxsD96pY9P5QMrBCRTcAa4F1V/eByv5k9Sm+MMQEq0M7AjTHGuFmBG2NMgLICN8aYAGUFbowxAcoK3BhjApQVuDHGBCgrcGOMCVD/H23p7o5SUFayAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict = {W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "    \n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15.706568 [-0.05919671]\n",
      "1 4.467646 [0.43509507]\n",
      "2 1.2707973 [0.69871736]\n",
      "3 0.36147106 [0.83931595]\n",
      "4 0.10281855 [0.9143018]\n",
      "5 0.029246092 [0.9542943]\n",
      "6 0.008318919 [0.9756236]\n",
      "7 0.0023662644 [0.9869993]\n",
      "8 0.0006730787 [0.99306625]\n",
      "9 0.0001914546 [0.996302]\n",
      "10 5.4457934e-05 [0.99802774]\n",
      "11 1.548886e-05 [0.99894816]\n",
      "12 4.406077e-06 [0.999439]\n",
      "13 1.2534173e-06 [0.9997008]\n",
      "14 3.564959e-07 [0.99984044]\n",
      "15 1.0142492e-07 [0.9999149]\n",
      "16 2.8912567e-08 [0.9999546]\n",
      "17 8.181317e-09 [0.9999758]\n",
      "18 2.3467415e-09 [0.99998707]\n",
      "19 6.692744e-10 [0.9999931]\n",
      "20 1.8856383e-10 [0.9999963]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "# derivative: W -= learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict = {X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict = {X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "10 [14.014359, 2.5015385, [(14.01436, 2.5015385)]]\n",
      "20 [5.260776, 1.5636545, [(5.260776, 1.5636545)]]\n",
      "30 [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]]\n",
      "40 [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]]\n",
      "50 [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]]\n",
      "60 [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]]\n",
      "70 [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]]\n",
      "80 [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]]\n",
      "90 [0.005525271, 1.000592, [(0.0055252714, 1.000592)]]\n"
     ]
    }
   ],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "\n",
    "gvs = optimizer.compute_gradients(cost, [W])\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    if step % 10 == 0:\n",
    "        print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 COST:  119749.71 \n",
      "PREDICTION\n",
      " [-163.92798 -162.21783 -191.16573 -184.44514 -153.36331]\n",
      "200 COST:  608.6481 \n",
      "PREDICTION\n",
      " [156.21582 173.20241 200.03894 175.82584 159.47467]\n",
      "400 COST:  608.18317 \n",
      "PREDICTION\n",
      " [155.94875 173.24278 200.08333 175.81667 159.6602 ]\n",
      "600 COST:  607.79626 \n",
      "PREDICTION\n",
      " [155.71123 173.27367 200.11961 175.81535 159.82661]\n",
      "800 COST:  607.47107 \n",
      "PREDICTION\n",
      " [155.49974 173.29642 200.1489  175.8207  159.97614]\n",
      "1000 COST:  607.1952 \n",
      "PREDICTION\n",
      " [155.31126 173.3122  200.17216 175.83168 160.11073]\n",
      "1200 COST:  606.9583 \n",
      "PREDICTION\n",
      " [155.14305 173.32196 200.19016 175.84734 160.23206]\n",
      "1400 COST:  606.753 \n",
      "PREDICTION\n",
      " [154.99275 173.32663 200.20366 175.86693 160.34166]\n",
      "1600 COST:  606.57294 \n",
      "PREDICTION\n",
      " [154.85826 173.32695 200.21327 175.88971 160.44086]\n",
      "1800 COST:  606.41345 \n",
      "PREDICTION\n",
      " [154.73778 173.3236  200.21954 175.91513 160.5308 ]\n",
      "2000 COST:  606.2711 \n",
      "PREDICTION\n",
      " [154.62964 173.31715 200.22298 175.94266 160.61253]\n"
     ]
    }
   ],
   "source": [
    "x1_data = [77., 84., 99., 94., 83.]\n",
    "x2_data = [86., 79., 93., 90., 71.]\n",
    "x3_data = [73., 84., 96., 81., 76.]\n",
    "y_data = [164., 198., 157., 173., 182.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name = 'score1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'score2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'score3')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict = {x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, \"COST: \", cost_val, \"\\nPREDICTION\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 COST:  10700.066 \n",
      "PREDICTION\n",
      " [[62.080982]\n",
      " [88.255165]\n",
      " [55.74226 ]\n",
      " [60.375523]\n",
      " [91.82511 ]]\n",
      "200 COST:  106.16471 \n",
      "PREDICTION\n",
      " [[169.84303]\n",
      " [193.80444]\n",
      " [162.35092]\n",
      " [154.17613]\n",
      " [191.80354]]\n",
      "400 COST:  99.307304 \n",
      "PREDICTION\n",
      " [[171.23405]\n",
      " [193.19322]\n",
      " [162.36111]\n",
      " [154.99431]\n",
      " [190.25551]]\n",
      "600 COST:  95.37016 \n",
      "PREDICTION\n",
      " [[172.17207]\n",
      " [192.87039]\n",
      " [162.1839 ]\n",
      " [155.57071]\n",
      " [189.28712]]\n",
      "800 COST:  92.72324 \n",
      "PREDICTION\n",
      " [[172.82504]\n",
      " [192.7218 ]\n",
      " [161.90384]\n",
      " [155.99295]\n",
      " [188.67743]]\n",
      "1000 COST:  90.72129 \n",
      "PREDICTION\n",
      " [[173.29686]\n",
      " [192.67723]\n",
      " [161.57208]\n",
      " [156.31541]\n",
      " [188.28996]]\n",
      "1200 COST:  89.09835 \n",
      "PREDICTION\n",
      " [[173.65215]\n",
      " [192.69359]\n",
      " [161.2195 ]\n",
      " [156.572  ]\n",
      " [188.04042]]\n",
      "1400 COST:  87.734924 \n",
      "PREDICTION\n",
      " [[173.93108]\n",
      " [192.74449]\n",
      " [160.8643 ]\n",
      " [156.78398]\n",
      " [187.87672]]\n",
      "1600 COST:  86.570114 \n",
      "PREDICTION\n",
      " [[174.15866]\n",
      " [192.81393]\n",
      " [160.51706]\n",
      " [156.96466]\n",
      " [187.76672]]\n",
      "1800 COST:  85.567505 \n",
      "PREDICTION\n",
      " [[174.35075]\n",
      " [192.8921 ]\n",
      " [160.18358]\n",
      " [157.12257]\n",
      " [187.69043]]\n",
      "2000 COST:  84.70165 \n",
      "PREDICTION\n",
      " [[174.51738]\n",
      " [192.97325]\n",
      " [159.86691]\n",
      " [157.26321]\n",
      " [187.63553]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[77., 84., 99.], [94., 83., 86.], [79., 93., 90.],\n",
    "          [71., 73., 84.], [96., 81., 76.]]\n",
    "y_data = [[164.], [198.], [157.], [173.], [182.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name = 'score')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "          \n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict = {X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, \"COST: \", cost_val, \"\\nPREDICTION\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 COST:  49637.55 \n",
      "PREDICTION\n",
      " [[-53.404346]\n",
      " [-48.519722]\n",
      " [-46.625946]\n",
      " [-45.879276]\n",
      " [-43.343025]]\n",
      "200 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "400 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "600 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "800 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1000 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1200 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1400 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1600 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1800 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "2000 COST:  nan \n",
      "PREDICTION\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[77., 84., 99.], [94., 83., 86.], [79., 93., 90.],\n",
    "          [71., 73., 84.], [96., 81., 76.]]\n",
    "y_data = [[164.], [198.], [157.], [173.], [182.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name = 'score')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1.0)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "          \n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict = {X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, \"COST: \", cost_val, \"\\nPREDICTION\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 COST:  58320.305 \n",
      "PREDICTION\n",
      " [[-68.935104]\n",
      " [-57.647236]\n",
      " [-92.480835]\n",
      " [-57.0184  ]\n",
      " [-56.407444]]\n",
      "200 COST:  58220.15 \n",
      "PREDICTION\n",
      " [[-68.72197 ]\n",
      " [-57.432003]\n",
      " [-92.2663  ]\n",
      " [-56.831573]\n",
      " [-56.200546]]\n",
      "400 COST:  58120.082 \n",
      "PREDICTION\n",
      " [[-68.50886 ]\n",
      " [-57.216743]\n",
      " [-92.051765]\n",
      " [-56.64475 ]\n",
      " [-55.99365 ]]\n",
      "600 COST:  58020.105 \n",
      "PREDICTION\n",
      " [[-68.29573]\n",
      " [-57.00151]\n",
      " [-91.83724]\n",
      " [-56.45791]\n",
      " [-55.78675]]\n",
      "800 COST:  57920.406 \n",
      "PREDICTION\n",
      " [[-68.082985]\n",
      " [-56.786724]\n",
      " [-91.62309 ]\n",
      " [-56.271435]\n",
      " [-55.580296]]\n",
      "1000 COST:  57821.074 \n",
      "PREDICTION\n",
      " [[-67.87077 ]\n",
      " [-56.57259 ]\n",
      " [-91.4095  ]\n",
      " [-56.085457]\n",
      " [-55.374542]]\n",
      "1200 COST:  57721.824 \n",
      "PREDICTION\n",
      " [[-67.65857 ]\n",
      " [-56.358475]\n",
      " [-91.19591 ]\n",
      " [-55.89948 ]\n",
      " [-55.16879 ]]\n",
      "1400 COST:  57622.676 \n",
      "PREDICTION\n",
      " [[-67.446365]\n",
      " [-56.144356]\n",
      " [-90.982315]\n",
      " [-55.7135  ]\n",
      " [-54.963036]]\n",
      "1600 COST:  57523.6 \n",
      "PREDICTION\n",
      " [[-67.23418 ]\n",
      " [-55.930218]\n",
      " [-90.76875 ]\n",
      " [-55.527523]\n",
      " [-54.757282]]\n",
      "1800 COST:  57424.613 \n",
      "PREDICTION\n",
      " [[-67.02196 ]\n",
      " [-55.716106]\n",
      " [-90.555145]\n",
      " [-55.341553]\n",
      " [-54.55153 ]]\n",
      "2000 COST:  57325.707 \n",
      "PREDICTION\n",
      " [[-66.80976 ]\n",
      " [-55.50197 ]\n",
      " [-90.34156 ]\n",
      " [-55.155575]\n",
      " [-54.345776]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[77., 84., 99.], [94., 83., 86.], [79., 93., 90.],\n",
    "          [71., 73., 84.], [96., 81., 76.]]\n",
    "y_data = [[164.], [198.], [157.], [173.], [182.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name = 'score')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-10)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "          \n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict = {X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, \"COST: \", cost_val, \"\\nPREDICTION\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4264284\n",
      "200 0.52479047\n",
      "400 0.49168554\n",
      "600 0.4678478\n",
      "800 0.44846871\n",
      "1000 0.4315563\n",
      "1200 0.4162048\n",
      "1400 0.40196976\n",
      "1600 0.38861665\n",
      "1800 0.3760117\n",
      "2000 0.36407188\n",
      "2200 0.3527402\n",
      "2400 0.34197342\n",
      "2600 0.33173582\n",
      "2800 0.32199642\n",
      "3000 0.31272683\n",
      "3200 0.30390045\n",
      "3400 0.295493\n",
      "3600 0.28748083\n",
      "3800 0.2798416\n",
      "4000 0.27255446\n",
      "4200 0.2655993\n",
      "4400 0.25895756\n",
      "4600 0.25261143\n",
      "4800 0.24654417\n",
      "5000 0.24074014\n",
      "5200 0.23518454\n",
      "5400 0.22986346\n",
      "5600 0.22476397\n",
      "5800 0.2198739\n",
      "6000 0.21518172\n",
      "6200 0.21067666\n",
      "6400 0.20634878\n",
      "6600 0.20218855\n",
      "6800 0.19818711\n",
      "7000 0.19433622\n",
      "7200 0.19062807\n",
      "7400 0.18705541\n",
      "7600 0.18361121\n",
      "7800 0.18028934\n",
      "8000 0.17708349\n",
      "8200 0.17398816\n",
      "8400 0.17099784\n",
      "8600 0.16810757\n",
      "8800 0.16531268\n",
      "9000 0.16260873\n",
      "9200 0.15999135\n",
      "9400 0.15745674\n",
      "9600 0.15500112\n",
      "9800 0.15262099\n",
      "10000 0.15031296\n",
      "\n",
      "Hypothesis:  [[0.03108484]\n",
      " [0.15931079]\n",
      " [0.3065129 ]\n",
      " [0.78063196]\n",
      " [0.93910134]\n",
      " [0.9800101 ]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'score')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict = {X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X: x_data, Y: y_data})\n",
    "\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
