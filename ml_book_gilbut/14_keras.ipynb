{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train, axis = 0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals) / std_val\n",
    "X_test_centered = (X_test - mean_vals) / std_val\n",
    "\n",
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_centered = X_train_centered.reshape(60000, 784)\n",
    "X_test_centered = X_test_centered.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original :  [5 0 4]\n",
      "encoded :  [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding labels\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "print('original : ', y_train[:3])\n",
    "print('encoded : ', y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feed-forward neural network modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input dim must be matched with datasets columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 50,\n",
    "                                input_dim = X_train_centered.shape[1],\n",
    "                                kernel_initializer = 'glorot_uniform',\n",
    "                                bias_initializer = 'zeros',\n",
    "                                activation = 'tanh'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 50,\n",
    "                                input_dim = X_train_centered.shape[1],\n",
    "                                kernel_initializer = 'glorot_uniform',\n",
    "                                bias_initializer = 'zeros',\n",
    "                                activation = 'tanh'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = y_train_onehot.shape[1],\n",
    "                                input_dim = 50,\n",
    "                                kernel_initializer = 'glorot_uniform',\n",
    "                                bias_initializer = 'zeros',\n",
    "                                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# before training model compile\n",
    "1. 최적화할 손실함수 정의\n",
    "2. 최적화에 사용할 경사 하강법 옵티마이저 선택\n",
    "3. 마지막 비용함수는 categorical_crossentropy\n",
    "4. 학습률 감쇠 상수 (decay)와 momentum 값 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr = 0.001, decay = 1e-7, momentum = .0)\n",
    "\n",
    "model.compile(optimizer = sgd_optimizer,\n",
    "              loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit method\n",
    "1. mini_batch 경사하강법 적용 (batch_size)\n",
    "2. verbose = 1 : 훈련하는 동안 비용 함수의 최적화 과정을 따라간다는 뜻\n",
    "3. validation_split : 원하는 비율만큼의 훈련데이터를 검증에 사용해 과대적합 모니터링 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "844/844 [==============================] - 1s 885us/step - loss: 1.5735 - val_loss: 1.0565\n",
      "Epoch 2/50\n",
      "844/844 [==============================] - 1s 752us/step - loss: 0.9603 - val_loss: 0.7510\n",
      "Epoch 3/50\n",
      "844/844 [==============================] - 1s 734us/step - loss: 0.7553 - val_loss: 0.6090\n",
      "Epoch 4/50\n",
      "844/844 [==============================] - 1s 773us/step - loss: 0.6452 - val_loss: 0.5260\n",
      "Epoch 5/50\n",
      "844/844 [==============================] - 1s 776us/step - loss: 0.5754 - val_loss: 0.4711\n",
      "Epoch 6/50\n",
      "844/844 [==============================] - 1s 766us/step - loss: 0.5265 - val_loss: 0.4319\n",
      "Epoch 7/50\n",
      "844/844 [==============================] - 1s 760us/step - loss: 0.4901 - val_loss: 0.4024\n",
      "Epoch 8/50\n",
      "844/844 [==============================] - 1s 769us/step - loss: 0.4617 - val_loss: 0.3791\n",
      "Epoch 9/50\n",
      "844/844 [==============================] - 1s 737us/step - loss: 0.4389 - val_loss: 0.3604\n",
      "Epoch 10/50\n",
      "844/844 [==============================] - 1s 755us/step - loss: 0.4200 - val_loss: 0.3448\n",
      "Epoch 11/50\n",
      "844/844 [==============================] - 1s 764us/step - loss: 0.4040 - val_loss: 0.3317\n",
      "Epoch 12/50\n",
      "844/844 [==============================] - 1s 757us/step - loss: 0.3903 - val_loss: 0.3204\n",
      "Epoch 13/50\n",
      "844/844 [==============================] - 1s 736us/step - loss: 0.3783 - val_loss: 0.3106\n",
      "Epoch 14/50\n",
      "844/844 [==============================] - 1s 742us/step - loss: 0.3677 - val_loss: 0.3019\n",
      "Epoch 15/50\n",
      "844/844 [==============================] - 1s 749us/step - loss: 0.3581 - val_loss: 0.2941\n",
      "Epoch 16/50\n",
      "844/844 [==============================] - 1s 750us/step - loss: 0.3496 - val_loss: 0.2872\n",
      "Epoch 17/50\n",
      "844/844 [==============================] - 1s 746us/step - loss: 0.3418 - val_loss: 0.2809\n",
      "Epoch 18/50\n",
      "844/844 [==============================] - 1s 752us/step - loss: 0.3347 - val_loss: 0.2752\n",
      "Epoch 19/50\n",
      "844/844 [==============================] - 1s 771us/step - loss: 0.3281 - val_loss: 0.2699\n",
      "Epoch 20/50\n",
      "844/844 [==============================] - 1s 743us/step - loss: 0.3220 - val_loss: 0.2650\n",
      "Epoch 21/50\n",
      "844/844 [==============================] - 1s 744us/step - loss: 0.3163 - val_loss: 0.2605\n",
      "Epoch 22/50\n",
      "844/844 [==============================] - 1s 744us/step - loss: 0.3110 - val_loss: 0.2562\n",
      "Epoch 23/50\n",
      "844/844 [==============================] - 1s 753us/step - loss: 0.3060 - val_loss: 0.2523\n",
      "Epoch 24/50\n",
      "844/844 [==============================] - 1s 745us/step - loss: 0.3013 - val_loss: 0.2485\n",
      "Epoch 25/50\n",
      "844/844 [==============================] - 1s 743us/step - loss: 0.2968 - val_loss: 0.2451\n",
      "Epoch 26/50\n",
      "844/844 [==============================] - 1s 754us/step - loss: 0.2926 - val_loss: 0.2419\n",
      "Epoch 27/50\n",
      "844/844 [==============================] - 1s 754us/step - loss: 0.2886 - val_loss: 0.2387\n",
      "Epoch 28/50\n",
      "844/844 [==============================] - 1s 767us/step - loss: 0.2847 - val_loss: 0.2357\n",
      "Epoch 29/50\n",
      "844/844 [==============================] - 1s 747us/step - loss: 0.2810 - val_loss: 0.2329\n",
      "Epoch 30/50\n",
      "844/844 [==============================] - 1s 748us/step - loss: 0.2775 - val_loss: 0.2302\n",
      "Epoch 31/50\n",
      "844/844 [==============================] - 1s 744us/step - loss: 0.2741 - val_loss: 0.2277\n",
      "Epoch 32/50\n",
      "844/844 [==============================] - 1s 751us/step - loss: 0.2709 - val_loss: 0.2252\n",
      "Epoch 33/50\n",
      "844/844 [==============================] - 1s 798us/step - loss: 0.2677 - val_loss: 0.2230\n",
      "Epoch 34/50\n",
      "844/844 [==============================] - 1s 755us/step - loss: 0.2647 - val_loss: 0.2207\n",
      "Epoch 35/50\n",
      "844/844 [==============================] - 1s 759us/step - loss: 0.2618 - val_loss: 0.2186\n",
      "Epoch 36/50\n",
      "844/844 [==============================] - 1s 760us/step - loss: 0.2590 - val_loss: 0.2164\n",
      "Epoch 37/50\n",
      "844/844 [==============================] - 1s 760us/step - loss: 0.2563 - val_loss: 0.2144\n",
      "Epoch 38/50\n",
      "844/844 [==============================] - 1s 763us/step - loss: 0.2536 - val_loss: 0.2124\n",
      "Epoch 39/50\n",
      "844/844 [==============================] - 1s 760us/step - loss: 0.2510 - val_loss: 0.2106\n",
      "Epoch 40/50\n",
      "844/844 [==============================] - 1s 759us/step - loss: 0.2485 - val_loss: 0.2088\n",
      "Epoch 41/50\n",
      "844/844 [==============================] - 1s 769us/step - loss: 0.2461 - val_loss: 0.2071\n",
      "Epoch 42/50\n",
      "844/844 [==============================] - 1s 775us/step - loss: 0.2438 - val_loss: 0.2055\n",
      "Epoch 43/50\n",
      "844/844 [==============================] - 1s 779us/step - loss: 0.2414 - val_loss: 0.2038\n",
      "Epoch 44/50\n",
      "844/844 [==============================] - 1s 765us/step - loss: 0.2392 - val_loss: 0.2022\n",
      "Epoch 45/50\n",
      "844/844 [==============================] - 1s 772us/step - loss: 0.2370 - val_loss: 0.2007\n",
      "Epoch 46/50\n",
      "844/844 [==============================] - 1s 763us/step - loss: 0.2349 - val_loss: 0.1992\n",
      "Epoch 47/50\n",
      "844/844 [==============================] - 1s 766us/step - loss: 0.2328 - val_loss: 0.1978\n",
      "Epoch 48/50\n",
      "844/844 [==============================] - 1s 786us/step - loss: 0.2308 - val_loss: 0.1964\n",
      "Epoch 49/50\n",
      "844/844 [==============================] - 1s 778us/step - loss: 0.2288 - val_loss: 0.1950\n",
      "Epoch 50/50\n",
      "844/844 [==============================] - 1s 768us/step - loss: 0.2268 - val_loss: 0.1937\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_centered, y_train_onehot,\n",
    "                    batch_size = 64, epochs = 50,\n",
    "                    verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 3개:  [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.argmax(model.predict(X_train_centered, verbose = 0), axis = -1)\n",
    "print('첫 3개: ', y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도 :  93.785\n",
      "테스트 정확도 :  93.43\n"
     ]
    }
   ],
   "source": [
    "correct_preds = np.sum(y_train == y_train_pred, axis = 0)\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "\n",
    "print('훈련 정확도 : ', round((train_acc * 100), 3))\n",
    "\n",
    "y_test_pred = np.argmax(model.predict(X_test_centered, verbose = 0), axis = -1)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis = 0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "\n",
    "print('테스트 정확도 : ', round((test_acc * 100), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low = -2, high = 2, size = 200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc = 0.0,\n",
    "                             scale = (0.5 + t*t/3),\n",
    "                             size = None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x - 0.84 + np.array(y)\n",
    "\n",
    "x, y = make_random_data()\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras에서는 fit할 때, 간단한 설정으로 검증세트를 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7564 - val_loss: 0.9028\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7556 - val_loss: 0.9020\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9053\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9084\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9065\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7567 - val_loss: 0.9035\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9049\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9025\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9019\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9012\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7571 - val_loss: 0.8989\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7566 - val_loss: 0.8987\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7584 - val_loss: 0.9016\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9023\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9004\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7571 - val_loss: 0.9015\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9081\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9048\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7556 - val_loss: 0.9032\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7576 - val_loss: 0.9009\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7570 - val_loss: 0.9024\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7573 - val_loss: 0.9002\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7572 - val_loss: 0.9001\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9030\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9029\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9006\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7560 - val_loss: 0.9032\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7569 - val_loss: 0.9088\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7563 - val_loss: 0.9050\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9021\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7561 - val_loss: 0.9030\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7581 - val_loss: 0.9032\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7574 - val_loss: 0.9029\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.9024\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.9022\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7582 - val_loss: 0.9011\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7561 - val_loss: 0.9005\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7573 - val_loss: 0.8985\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7561 - val_loss: 0.8998\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7576 - val_loss: 0.9014\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7569 - val_loss: 0.8993\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7556 - val_loss: 0.9006\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.9004\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7571 - val_loss: 0.9003\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7560 - val_loss: 0.8981\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7573 - val_loss: 0.8975\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7568 - val_loss: 0.8978\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7575 - val_loss: 0.8988\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9008\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7561 - val_loss: 0.9004\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7576 - val_loss: 0.8982\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9010\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.8992\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9021\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9033\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7577 - val_loss: 0.9007\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9051\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9071\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9022\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9020\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9031\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9087\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9099\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7580 - val_loss: 0.9128\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7564 - val_loss: 0.9108\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9083\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9058\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9060\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9069\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9112\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9090\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9101\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9037\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9017\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9009\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9019\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9024\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9030\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9012\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.9009\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9014\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9040\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9059\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9047\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9079\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7578 - val_loss: 0.9053\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9055\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9100\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9052\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9038\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9019\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9029\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9046\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9049\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9054\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9061\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9104\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9118\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9082\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9039\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9029\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9019\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.8995\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8984\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9013\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.8987\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9002\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9009\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.8986\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9002\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.8997\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9089\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9067\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9069\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9173\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9159\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9213\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9153\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9113\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9100\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 0.9096\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9101\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9131\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9156\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9157\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9158\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9154\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9146\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9118\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7563 - val_loss: 0.9116\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9129\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7574 - val_loss: 0.9141\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9111\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9136\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9109\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9099\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 0.9082\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9022\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.8995\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7588 - val_loss: 0.9049\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9017\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9023\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9026\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9054\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9062\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7572 - val_loss: 0.9069\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9044\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9030\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.8987\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.8992\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7582 - val_loss: 0.9015\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8978\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8961\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.8972\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.8962\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.8913\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8931\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.8921\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.8948\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.8933\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.8898\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7600 - val_loss: 0.8928\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7582 - val_loss: 0.8921\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.8954\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8989\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.8956\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7585 - val_loss: 0.8950\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8997\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.8980\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7589 - val_loss: 0.8981\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7582 - val_loss: 0.9016\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9096\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7556 - val_loss: 0.9105\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9077\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9088\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9088\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9074\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9057\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9058\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9021\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9027\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9052\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9035\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9046\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9022\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9000\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9062\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9083\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9044\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9046\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9014\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9036\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9060\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7591 - val_loss: 0.9038\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9020\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9005\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7567 - val_loss: 0.9012\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7571 - val_loss: 0.9033\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9037\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7576 - val_loss: 0.9073\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7562 - val_loss: 0.9080\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7573 - val_loss: 0.9094\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9141\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7561 - val_loss: 0.9150\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9219\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7589 - val_loss: 0.9213\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7573 - val_loss: 0.9198\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.9225\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7572 - val_loss: 0.9231\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9231\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9202\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9183\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7582 - val_loss: 0.9138\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9164\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9161\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9149\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9127\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9098\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9092\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9046\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9031\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9048\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9006\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8987\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7577 - val_loss: 0.8997\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9038\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9059\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9036\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9055\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9100\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9067\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9119\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9106\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9098\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9125\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9158\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9225\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9229\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9265\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7583 - val_loss: 0.9215\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 0.9280\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.9245\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7601 - val_loss: 0.9238\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7587 - val_loss: 0.9285\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7587 - val_loss: 0.9212\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7584 - val_loss: 0.9188\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9207\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7595 - val_loss: 0.9191\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7587 - val_loss: 0.9241\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7588 - val_loss: 0.9206\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9167\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9192\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7577 - val_loss: 0.9216\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7586 - val_loss: 0.9201\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.087 - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9163\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7589 - val_loss: 0.9071\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9052\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9044\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9068\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9037\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9027\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9047\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.9047\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9033\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.8999\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9016\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9038\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7580 - val_loss: 0.9024\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.8990\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.8993\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.8978\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.8956\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7577 - val_loss: 0.8968\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8978\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.8961\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9019\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7580 - val_loss: 0.9021\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.9017\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9018\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9013\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9012\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9008\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9002\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9037\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9061\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9084\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9048\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9087\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9095\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9126\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9144\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9130\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9126\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9198\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9211\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 0.9190\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7583 - val_loss: 0.9147\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.9135\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.9115\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7585 - val_loss: 0.9141\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7576 - val_loss: 0.9182\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9189\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7568 - val_loss: 0.9157\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9130\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9117\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9136\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9133\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9099\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9107\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9054\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9054\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9071\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7556 - val_loss: 0.9056\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9081\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9093\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9074\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9064\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9052\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7580 - val_loss: 0.9088\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9116\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9114\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7588 - val_loss: 0.9128\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9115\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9150\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9126\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9072\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9065\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9049\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9049\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9052\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9085\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9089\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9066\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9077\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9078\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9021\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9016\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9019\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9028\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9025\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9086\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9089\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9089\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9075\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9040\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9081\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9094\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9089\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 0.9084\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9099\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9128\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9135\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9118\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9134\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9119\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9129\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9112\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9123\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9176\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9159\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9113\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9097\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.9084\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9112\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9120\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9106\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9144\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9156\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9126\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.9181\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 0.9187\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9224\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9159\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9122\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9126\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9083\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7588 - val_loss: 0.9072\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.9067\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9063\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9039\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9053\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.9039\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9018\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9059\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9076\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9049\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9047\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9091\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7600 - val_loss: 0.9127\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9086\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9061\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9116\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9105\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9051\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9031\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9106\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9052\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9019\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9001\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.8979\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8966\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.8968\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.8947\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.8935\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.8980\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.8959\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7568 - val_loss: 0.8972\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7587 - val_loss: 0.8975\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7590 - val_loss: 0.8968\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.8942\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.8955\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8943\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.8916\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.8980\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9022\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.9005\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9005\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8970\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8958\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.8970\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8937\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.8969\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.8946\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8960\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.8987\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.8991\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9005\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.8995\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8982\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.8983\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8959\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9014\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9011\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8987\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.8992\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.9014\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8991\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.8999\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.9031\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7584 - val_loss: 0.9028\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9042\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9042\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9045\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9056\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9045\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9052\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9032\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9061\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9031\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7578 - val_loss: 0.9028\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9025\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9048\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9078\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9119\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7565 - val_loss: 0.9142\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9156\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9117\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9124\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.9099\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9086\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9123\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.9106\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9082\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9073\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7577 - val_loss: 0.9093\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9080\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.9074\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7559 - val_loss: 0.9100\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9102\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.9064\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.9064\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.9082\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9098\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9081\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9118\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9096\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.9103\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7559 - val_loss: 0.9050\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9058\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7571 - val_loss: 0.9051\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 0.9025\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7582 - val_loss: 0.9016\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9048\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9051\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.9051\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.9031\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - val_loss: 0.9011\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7567 - val_loss: 0.8999\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7560 - val_loss: 0.9006\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7563 - val_loss: 0.8963\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 0.8964\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - val_loss: 0.8970\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7564 - val_loss: 0.8994\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7573 - val_loss: 0.8985\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7570 - val_loss: 0.8992\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.8974\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - val_loss: 0.8950\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7589 - val_loss: 0.8944\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "history = model.fit(x_train, y_train, epochs = 500,\n",
    "                    validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input = tf.keras.Input(shape=(1,))\n",
    "output = tf.keras.layers.Dense(1)(input)\n",
    "\n",
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치만 저장\n",
    "- 모델 구조층 다시 생성해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_weights.h5')\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_dim = 1))\n",
    "model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "\n",
    "model.load_weights('simple_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set evaluation\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 전체 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelcheckpoint 콜백 : 최고의 성능을 내는 가중치 저장\n",
    "### earlyStopping 콜백 : 성능이 개선되지 않을 때 훈련을 멈춤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### monitor = 'val_loss' : 검증 데이터 손실을 모니터 하면서 save_best_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_dim = 1))\n",
    "\n",
    "callback_list = [tf.keras.callbacks.ModelCheckpoint(filepath = 'my_model.h5',\n",
    "                                                    monitor = 'val_loss',\n",
    "                                                    save_best_only = True),\n",
    "                 tf.keras.callbacks.EarlyStopping(patience = 5)]\n",
    "history = model.fit(x_train, y_train, epochs = 500,\n",
    "                    validation_split = 0.2, callbacks = callback_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf23",
   "language": "python",
   "name": "tf23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
